--- 
layout: post
title: kaggle建模赛之手写数字识别
tags: 
- 建模
- kaggle
status: publish
type: post
published: true
---

> 今天大数据的火热程度简直烫手。我始终认为大数据不过是个炒作的伪概念，10多年前刚接触到统计这门专业的时候，大学教授们说的最多的词语还只是“数据仓库”，商业领域干的最多的事情不过是KDD（knowled discovery in database)，啤酒尿不湿的故事已经快被玩坏了，说到底还是数据挖掘的范畴。没有合适的分析方法，数据量再大也只能是负担，数据源充满了垃圾，分析方法再高深，结果依然是垃圾。

所以东家常洗脑我们说“We don't talk about big data, we say smart data"，你看德国人一点也不（Lao)傻(shi)，我常常对于语言表达能力可以产生的威力充满了敬畏。

最近注册了Kaggle账号，试玩了一把[Digit Recognizer](https://www.kaggle.com/c/digit-recognizer "Digit Recognizer")的比赛项目。主要有3大感慨：

- 在这个牛人辈出的时代，一定要谦虚
- 黑猫白猫抓到老鼠就是好猫(不管是统计学习方法还是机器学习方法，能解决问题就是好方法）
- 想法始终比方法更重要


整个比赛给出两套数据，训练集和测试集，比赛要求通过利用训练集所包含的42,000幅图片来训练模型，并通过模型预测测试集中的28,000幅图片到底是什么数字。

随机抽了100张图片数据，打印出来大概长成下面的样子（这很像是西欧人的手写体），如果奖金还在又或者还有的话，最完美的解决办法就是把测试集打印出来，找几个兼职人肉识别一下，准确率100%绝对排第一，奖金到手，项目结束。
<img src="/upload/pic/Viz.png"/>

每一副图片实质上对应一个矩阵，元素则是255位RGB颜色值代码，既然如此，那么可以采用数理统计的方法来尝试解决。这里本质上是个监督式分类的问题，每幅图片大小相近，书写相对清晰，可以说数据源本身就有比较好的特征，噪声较小，理论上采用比较简单的逻辑模型应该也会得到比较好的结果（没有尝试，有待验证）。

分别尝试过3个模型原型，坊间传言特征决定了模型的高度，参数只是算法逼近这个高度的手段，对此深有体会。这里不考虑参数调优，按经验建模，给出如下结果：

1. 随机森林（RandomForest），构建500棵树，测试准确率94.701%,大概排名1000+,多训练几棵树有可能达到更好效果。
2. Xgboost，训练2000棵树，在已有特征范围内loss function已达到极限，测试集准确率达到97.271%，排名658.
3. SVC，准确率进一步提升97.543%, 目前最好排名424
<img src="/upload/pic/rank1.PNG"/>

模型的选择对于准确率的影响并没有想象中那么重要，参数调优有可能进一步提升预测准确率，但只是锦上添花效果是有限的。因特征比较清晰，整个过程并未涉及特征的进一步处理，从第一名准确率100%来看，尚有很大提升空间。特征很重要，以后有时间再看。

